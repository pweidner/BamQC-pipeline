# Import necessary modules
import os
import glob
import subprocess
import yaml
import pandas as pd
from utils import extract_alignment_metrics

# ASCII art for BamQC-BIH
print(r"""
 /$$$$$$$                           /$$$$$$   /$$$$$$        /$$$$$$$  /$$$$$$ /$$   /$$
| $$__  $$                         /$$__  $$ /$$__  $$      | $$__  $$|_  $$_/| $$  | $$
| $$  \ $$  /$$$$$$  /$$$$$$/$$$$ | $$  \ $$| $$  \__/      | $$  \ $$  | $$  | $$  | $$
| $$$$$$$  |____  $$| $$_  $$_  $$| $$  | $$| $$            | $$$$$$$   | $$  | $$$$$$$$
| $$__  $$  /$$$$$$$| $$ \ $$ \ $$| $$  | $$| $$            | $$__  $$  | $$  | $$__  $$
| $$  \ $$ /$$__  $$| $$ | $$ | $$| $$/$$ $$| $$    $$      | $$  \ $$  | $$  | $$  | $$
| $$$$$$$/|  $$$$$$$| $$ | $$ | $$|  $$$$$$/|  $$$$$$/      | $$$$$$$/ /$$$$$$| $$  | $$
|_______/  \_______/|__/ |__/ |__/ \____ $$$ \______/       |_______/ |______/|__/  |__/
                                        \__/                                                       
""")

# Load config file
configfile: "config/config.yaml"

# Define input and output directories, reference, etc.
data_location = config["data_location"]
output_location = config["output_location"]
ref = config["ref"]
reference_path = config["reference_path"]

# Print summary of parameters with color coding for clarity
print("Pipeline launched with the following parameters:")
print(f"- Data Location: \033[1;31m{data_location}\033[0m")
print(f"- Output Location: \033[1;32m{output_location}\033[0m")
print(f"- Reference Genome: \033[1;33m{ref}\033[0m")
print("")

# Define the file path to the reference genome file
reference_file = os.path.join(reference_path, f"{ref}")

# Define the list of samples based on the input BAM files.
# Using rsplit to handle cases where filenames contain multiple periods.
samples = [os.path.basename(f).rsplit(".sort.mdup", 1)[0] 
           for f in glob.glob(os.path.join(data_location, "*.sort.mdup.bam"))]

# Print the expanded pattern for debugging purposes
print("Expanding input files with the following pattern:")
print(os.path.join(config['output_location'], "stats-by-lib", "{sample}.qc.tsv.gz"))
print("")


#########################################
# Rule: all
# Final target rule that collects the cleaned alignment summary metrics.
#########################################
rule all:
    """
    Collect all final output files
    """
    input:    
        os.path.join(output_location, "alignment_summary_metrics.tsv")


#########################################
# Rule: alfred_qc
# Process each BAM file with Alfred to generate QC statistics.
#########################################
rule alfred_qc:
    input:
        bam = os.path.join(data_location, "{sample}.sort.mdup.bam"),
        reference = reference_file
    output:
        qc = os.path.join(output_location, "stats-by-lib", "{sample}.qc.tsv.gz")
    conda:
        "envs/qc_env.yaml"
    threads: 4  # Allocate additional threads for processing if needed.
    log:
        os.path.join(output_location, "logs", "{sample}.alfred_qc.log")
    shell:
        """
        # Create log directory if it doesn't exist
        mkdir -p {os.path.join(output_location, "logs")}
        echo "Processing sample: {wildcards.sample}" > {log}
        alfred qc -r {input.reference} -o {output.qc} {input.bam} >> {log} 2>&1
        """


#########################################
# Rule: aggregate_alignment_metrics
# Collect, process, and aggregate the QC metrics from all sample files.
#########################################
rule aggregate_alignment_metrics:
    input:
        qc_files = expand(os.path.join(output_location, "stats-by-lib", "{sample}.qc.tsv.gz"), sample=samples)
    output:
        summary = os.path.join(output_location, "alignment_summary_metrics.tsv")
    threads: 2
    run:
        import pandas as pd
        import os

        # List to store each sample's QC metrics as a dict.
        all_samples = []

        for qc_file in input.qc_files:
            # Extract the sample identifier.
            sample_id = os.path.basename(qc_file).split(".qc.tsv")[0]
            try:
                result = extract_alignment_metrics(qc_file)
            except Exception as e:
                print(f"Error processing {qc_file}: {e}")
                continue

            # Check if the result is already a dict.
            if isinstance(result, dict):
                sample_metrics = result
            else:
                # Assume the result is a tuple: (headers, values)
                headers, values = result
                sample_metrics = dict(zip(headers, values))

            # Ensure the sample (library) name is included:
            sample_metrics["Library"] = sample_id
            all_samples.append(sample_metrics)

        # Create a DataFrame from the list of dictionaries.
        df = pd.DataFrame(all_samples)

        # Reorder columns so that "Library" is the first column.
        if "Library" in df.columns:
            cols = list(df.columns)
            cols.remove("Library")
            df = df[["Library"] + cols]

        # Write the wide-format DataFrame to the output file.
        df.to_csv(output.summary, sep='\t', index=False)
