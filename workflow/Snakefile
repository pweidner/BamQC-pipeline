# Import necessary modules
import os
import glob
import subprocess
import yaml
import pandas as pd
from utils import extract_alignment_metrics

# ASCII art for BamQC-BIH
print(r"""
 /$$$$$$$                           /$$$$$$   /$$$$$$        /$$$$$$$  /$$$$$$ /$$   /$$
| $$__  $$                         /$$__  $$ /$$__  $$      | $$__  $$|_  $$_/| $$  | $$
| $$  \ $$  /$$$$$$  /$$$$$$/$$$$ | $$  \ $$| $$  \__/      | $$  \ $$  | $$  | $$  | $$
| $$$$$$$  |____  $$| $$_  $$_  $$| $$  | $$| $$            | $$$$$$$   | $$  | $$$$$$$$
| $$__  $$  /$$$$$$$| $$ \ $$ \ $$| $$  | $$| $$            | $$__  $$  | $$  | $$__  $$
| $$  \ $$ /$$__  $$| $$ | $$ | $$| $$/$$ $$| $$    $$      | $$  \ $$  | $$  | $$  | $$
| $$$$$$$/|  $$$$$$$| $$ | $$ | $$|  $$$$$$/|  $$$$$$/      | $$$$$$$/ /$$$$$$| $$  | $$
|_______/  \_______/|__/ |__/ |__/ \____ $$$ \______/       |_______/ |______/|__/  |__/
                                        \__/                                                       
""")

# Load config file
configfile: "config/config.yaml"

# Define input and output directories, reference, etc.
data_location = config["data_location"]
output_location = config["output_location"]
ref = config["ref"]
reference_path = config["reference_path"]

# Print summary of parameters with color coding for clarity
print("Pipeline launched with the following parameters:")
print(f"- Data Location: \033[1;31m{data_location}\033[0m")
print(f"- Output Location: \033[1;32m{output_location}\033[0m")
print(f"- Reference Genome: \033[1;33m{ref}\033[0m")
print("")

# Define the file path to the reference genome file
reference_file = os.path.join(reference_path, f"{ref}")

# Define the list of samples based on the input BAM files.
# Using rsplit to handle cases where filenames contain multiple periods.
samples = [os.path.basename(f).rsplit(".sort.mdup", 1)[0] 
           for f in glob.glob(os.path.join(data_location, "*.sort.mdup.bam"))]

# Print the expanded pattern for debugging purposes
print("Expanding input files with the following pattern:")
print(os.path.join(config['output_location'], "stats-by-lib", "{sample}.qc.tsv.gz"))
print("")


#########################################
# Rule: all
# Final target rule that collects the cleaned alignment summary metrics.
#########################################
rule all:
    """
    Collect all final output files
    """
    input:    
        os.path.join(output_location, "alignment_summary_metrics.tsv")


#########################################
# Rule: alfred_qc
# Process each BAM file with Alfred to generate QC statistics.
#########################################
rule alfred_qc:
    input:
        bam = os.path.join(data_location, "{sample}.sort.mdup.bam"),
        reference = reference_file
    output:
        qc = os.path.join(output_location, "stats-by-lib", "{sample}.qc.tsv.gz")
    conda:
        "envs/qc_env.yaml"
    threads: 4  # Allocate additional threads for processing if needed.
    log:
        os.path.join(output_location, "logs", "{sample}.alfred_qc.log")
    shell:
        """
        # Create log directory if it doesn't exist
        mkdir -p {os.path.join(output_location, "logs")}
        echo "Processing sample: {wildcards.sample}" > {log}
        alfred qc -r {input.reference} -o {output.qc} {input.bam} >> {log} 2>&1
        """


#########################################
# Rule: aggregate_alignment_metrics
# Collect, process, and aggregate the QC metrics from all sample files.
#########################################
rule aggregate_alignment_metrics:
    input:
        qc_files = expand(os.path.join(output_location, "stats-by-lib", "{sample}.qc.tsv.gz"), sample=samples)
    output:
        summary = os.path.join(output_location, "alignment_summary_metrics.tsv")
    threads: 2
    run:
        import pandas as pd
        import os
        import gzip

        all_samples = []  # list to collect per-sample dictionary of metrics

        for qc_file in input.qc_files:
            # Derive sample id from file name (e.g., A5091_L2_i301)
            sample_id = os.path.basename(qc_file).split(".qc.tsv")[0]
            header = None
            data_line = None
            try:
                with gzip.open(qc_file, 'rt') as f:
                    for line in f:
                        # Look for lines starting with "ME" (alignment summary metrics block)
                        if line.startswith("ME"):
                            tokens = line.strip().split("\t")
                            if header is None:
                                header = tokens
                            else:
                                data_line = tokens
                                break  # Stop after obtaining header and first data line
            except Exception as e:
                print(f"Error reading {qc_file}: {e}")
                continue

            if header is None or data_line is None:
                print(f"Could not find ME section in {qc_file}")
                continue

            # Both header and data_line include a first column "ME" then "Sample".
            # We want to drop these so that the resulting headers start with "Library".
            # For example:
            #   Original header: ["ME", "Sample", "Library", "#QCFail", "QCFailFraction", ...]
            #   Original data:   ["ME", "IBD-CD6", "A5091_L2_i301", "0", "0", ...]
            # We drop the first two elements.
            new_header = header[1:]
            new_data = data_line[1:]

            # Now, new_header[0] should be "Library" and new_data[0] its value.
            sample_metrics = dict(zip(new_header, new_data))
            all_samples.append(sample_metrics)

        # Build a DataFrame where each row is one sample (library).
        agg_df = pd.DataFrame(all_samples)

        # Make sure "Library" is the first column.
        if "Library" in agg_df.columns:
            cols = agg_df.columns.tolist()
            cols.remove("Library")
            agg_df = agg_df[["Library"] + cols]

        # Write the aggregated wide table to the output file.
        agg_df.to_csv(output.summary, sep="\t", index=False)
