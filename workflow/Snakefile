# Import necessary modules
import os
import glob
import subprocess
import yaml
import pandas as pd
from utils import extract_alignment_metrics

# ASCII art for BamQC-BIH
print(r"""
 /$$$$$$$                           /$$$$$$   /$$$$$$        /$$$$$$$  /$$$$$$ /$$   /$$
| $$__  $$                         /$$__  $$ /$$__  $$      | $$__  $$|_  $$_/| $$  | $$
| $$  \ $$  /$$$$$$  /$$$$$$/$$$$ | $$  \ $$| $$  \__/      | $$  \ $$  | $$  | $$  | $$
| $$$$$$$  |____  $$| $$_  $$_  $$| $$  | $$| $$            | $$$$$$$   | $$  | $$$$$$$$
| $$__  $$  /$$$$$$$| $$ \ $$ \ $$| $$  | $$| $$            | $$__  $$  | $$  | $$__  $$
| $$  \ $$ /$$__  $$| $$ | $$ | $$| $$/$$ $$| $$    $$      | $$  \ $$  | $$  | $$  | $$
| $$$$$$$/|  $$$$$$$| $$ | $$ | $$|  $$$$$$/|  $$$$$$/      | $$$$$$$/ /$$$$$$| $$  | $$
|_______/  \_______/|__/ |__/ |__/ \____ $$$ \______/       |_______/ |______/|__/  |__/
                                        \__/                                                       
""")

# Load config file
configfile: "config/config.yaml"

# Define input and output directories, reference, etc.
data_location = config["data_location"]
output_location = config["output_location"]
ref = config["ref"]
reference_path = config["reference_path"]

# Print summary of parameters with color coding for clarity
print("Pipeline launched with the following parameters:")
print(f"- Data Location: \033[1;31m{data_location}\033[0m")
print(f"- Output Location: \033[1;32m{output_location}\033[0m")
print(f"- Reference Genome: \033[1;33m{ref}\033[0m")
print("")

# Define the file path to the reference genome file
reference_file = os.path.join(reference_path, f"{ref}")

# Define the list of samples based on the input BAM files.
# Using rsplit to handle cases where filenames contain multiple periods.
samples = [os.path.basename(f).rsplit(".sort.mdup", 1)[0] 
           for f in glob.glob(os.path.join(data_location, "*.sort.mdup.bam"))]

# Print the expanded pattern for debugging purposes
print("Expanding input files with the following pattern:")
print(os.path.join(config['output_location'], "stats-by-lib", "{sample}.qc.tsv.gz"))
print("")


#########################################
# Rule: all
# Final target rule that collects the cleaned alignment summary metrics.
#########################################
rule all:
    """
    Collect all final output files
    """
    input:    
        os.path.join(output_location, "alignment_summary_metrics_cleaned.tsv")


#########################################
# Rule: alfred_qc
# Process each BAM file with Alfred to generate QC statistics.
#########################################
rule alfred_qc:
    input:
        bam = os.path.join(data_location, "{sample}.sort.mdup.bam"),
        reference = reference_file
    output:
        qc = os.path.join(output_location, "stats-by-lib", "{sample}.qc.tsv.gz")
    conda:
        "envs/qc_env.yaml"
    threads: 4  # Allocate additional threads for processing if needed.
    log:
        os.path.join(output_location, "logs", "{sample}.alfred_qc.log")
    shell:
        """
        # Create log directory if it doesn't exist
        mkdir -p {os.path.join(output_location, "logs")}
        echo "Processing sample: {wildcards.sample}" > {log}
        alfred qc -r {input.reference} -o {output.qc} {input.bam} >> {log} 2>&1
        """


#########################################
# Rule: aggregate_alignment_metrics
# Collect, process, and aggregate the QC metrics from all sample files.
#########################################
rule aggregate_alignment_metrics:
    input:
        qc_files = expand(os.path.join(output_location, "stats-by-lib", "{sample}.qc.tsv.gz"), sample=samples)
    output:
        summary = os.path.join(output_location, "alignment_summary_metrics.tsv")
    threads: 2
    run:
        import pandas as pd
        import os
        
        rows = []  # list to store each sample's metrics as a dict
        
        # Loop over each QC file
        for qc_file in input.qc_files:
            # Extract the sample identifier from the filename.
            # Assumes file naming like <sample>.qc.tsv.gz, adjust if necessary.
            sample_id = os.path.basename(qc_file).split(".qc.tsv")[0]
            try:
                sample_metrics = extract_alignment_metrics(qc_file)
            except Exception as e:
                print(f"Error processing {qc_file}: {e}")
                continue
            
            # Add the sample identifier as a key-value pair.
            sample_metrics["Library"] = sample_id
            rows.append(sample_metrics)
        
        # Create a DataFrame with one row per sample.
        df = pd.DataFrame(rows)
        
        # Reorder columns so that the "Library" column appears first.
        if "Library" in df.columns:
            cols = df.columns.tolist()
            cols.remove("Library")
            df = df[["Library"] + cols]
        
        # Write the wide-format DataFrame to the summary output.
        df.to_csv(output.summary, sep='\t', index=False)
