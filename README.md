# BamQC-pipeline ğŸš€

A fast, reproducible **Snakemake** workflow for **QC of BAMs** â€” alignment stats, binned-coverage metrics, library complexity, and optional **Ashleyâ€™s QC**.

**Highlights**
- ğŸ§¬ **Alfred** alignment + error metrics  
- ğŸ§Š **Binned coverage** â†’ entropy, spikiness, GC bias  
- ğŸ“ˆ **preseq** library complexity curves  
- ğŸ§  **Ashleyâ€™s QC**: auto-merge existing labels/features or predict  
- ğŸ–¼ï¸ **Plots**: per-library PDFs + run summary  
- ğŸ—‚ï¸ **Clean outputs** with consistent join key `Library`

---

## âš™ï¸ 1. Installation

```bash
git clone https://github.com/pweidner/BamQC-pipeline.git
cd BamQC-pipeline
mamba create -n snakemake snakemake=7.32.0 -y
conda activate snakemake
```

> Tools used by rules are auto-installed from `workflow/envs/*.yaml` on first run.

---

## ğŸ§¾ 2. Configuration (`config/config.yaml`)

```yaml
ref: hg38
reference_path: /ref/dir               # contains hg38.fa (+.fai)
data_location:  /path/to/input         # FLAT: *.sort.mdup.bam; HIER: <sample>/bam/*.sort.mdup.bam
output_location: /path/to/output
window: 200000
plot: true

bam_ext: ".sort.mdup.bam"
tmp_dir: /tmp

ashleys:
  enabled: true
  bin: /abs/path/ashleys-qc/bin/ashleys.py
  model_path: /abs/path/ashleys-qc/models/svc_default.pkl
  win_sizes: [5000000,2000000,1000000,800000,600000,400000,200000]
  threads: 32
  mem_mb: 200000
  conda_env: envs/ashleys.yaml
```

**Discovery modes**
- **FLAT**: `data_location/*.sort.mdup.bam`
- **HIER**: `data_location/<SAMPLE>/bam/*.sort.mdup.bam`  
  â†’ auto-detected.

---

## â–¶ï¸ 3. Run

```bash
snakemake   --config ref=hg38 reference_path=/ref            data_location=/data/runA            output_location=/data/runA/bamqc   --profile workflow/profiles   --rerun-incomplete --keep-going
```

---

## ğŸ“‚ 4. Output structure

All paths relative to your `output_location`.

```
output_location/
â”œâ”€â”€ alignment_summary_metrics.tsv        # ğŸ§¬ Alfred summary across libraries
â”œâ”€â”€ final_qc.tsv                         # ğŸ§© Alfred + counts-based + preseq QC
â”œâ”€â”€ final_qc_with_ashleys.tsv            # ğŸ§  final_qc + Ashleyâ€™s columns
â”‚
â”œâ”€â”€ results/                             # ğŸ“Š deliverables
â”‚   â”œâ”€â”€ final_qc.tsv
â”‚   â”œâ”€â”€ final_qc_with_ashleys.tsv
â”‚   â””â”€â”€ alignment_summary_metrics.tsv
â”‚
â”œâ”€â”€ metadata/
â”‚   â””â”€â”€ library_map.tsv                  # cell <-> Library mapping
â”‚
â”œâ”€â”€ stats-by-lib/
â”‚   â””â”€â”€ {Library}.qc.tsv.gz              # per-lib Alfred output
â”‚
â”œâ”€â”€ binned/
â”‚   â””â”€â”€ {Library}.bins.tsv.gz            # windowed counts
â”‚
â”œâ”€â”€ qc-from-bins/
â”‚   â””â”€â”€ {Library}.counts_qc.tsv          # entropy/spikiness/GC-bias metrics
â”‚
â”œâ”€â”€ preseq/
â”‚   â””â”€â”€ {Library}.lc.tsv                 # library complexity curve
â”‚
â”œâ”€â”€ ashleys/
â”‚   â”œâ”€â”€ features.tsv                     # merged/computed Ashley features
â”‚   â”œâ”€â”€ features.norm.tsv                # features keyed by Library
â”‚   â””â”€â”€ prediction/
â”‚       â”œâ”€â”€ prediction.tsv               # merged labels or predictions
â”‚       â””â”€â”€ prediction.norm.tsv          # normalized to Library
â”‚
â””â”€â”€ plots/
    â”œâ”€â”€ per-lib-qc/{Library}.qc.pdf      # optional per-lib PDF
    â””â”€â”€ run_summary.pdf                  # optional run summary plot
```

---

## ğŸ§  5. Join keys

- Canonical key across all merges: **`Library`** (sample ID from BAM)
- `metadata/library_map.tsv` maps:
  ```
  cell                              Library
  A5455_L2_1001.sort.mdup.bam      OP-BB10-T_A5455_L2_1001
  ...
  ```
- `ashleys/prediction/prediction.norm.tsv` â†’ `Library, ashleys_prediction, ashleys_probability, ashleys_sample`
- `ashleys/features.norm.tsv` â†’ `Library, [feature columnsâ€¦]`

---

## ğŸ§¬ 6. Ashleyâ€™s integration

- If `*/cell_selection/labels.tsv` or similar exist â†’ merged into `ashleys/prediction/prediction.tsv`
- If `*/predictions/ashleys_features.tsv` exist â†’ merged into `ashleys/features.tsv`
- Otherwise, features + predictions are **computed** automatically  
- Everything is **normalized** to `Library` for merging

---

## ğŸ–¨ï¸ 7. Quick examples

**Run full QC**
```bash
snakemake --config ref=hg38 data_location=/bams output_location=/out --profile workflow/profiles
```

**Generate only plots**
```bash
snakemake plots/run_summary.pdf --profile workflow/profiles
```

**Recompute Ashley features only**
```bash
snakemake ashleys/features.tsv --cores 16
```

---

## ğŸ“š 8. Citations

- **Alfred** â€” Rausch *et al.*, *Genome Res* (2019)  
- **preseq** â€” Daley & Smith, *Bioinformatics* (2013)
- **ASHLEYS** - Gros *et al.*, *Bioinformatics* (2021)
- **bedtools** â€” Quinlan & Hall, *Bioinformatics* (2010)  
- **Snakemake** â€” KÃ¶ster & Rahmann, *Bioinformatics* (2012)

---

## ğŸ’¡ 9. Roadmap

- VerifyBamID / contamination checks  
- More GC/coverage plots (Lorenz, violin)  
- Optional HTML dashboard  

---

### â¤ï¸ Contributing

Please open issues or PRs with:
- your `config.yaml`
- the `snakemake` command used
- relevant logs under `logs/` or `errors/`

Happy QCâ€™ing! ğŸ§ªâœ¨
